{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6a98006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import handTracker as htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0d4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd2adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(CNNModel,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32,kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,32,kernel_size=3,stride=1)\n",
    "        self.conv3 = nn.Conv2d(32,64,kernel_size=3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(64*27*27,1024)\n",
    "        self.fc2 = nn.Linear(1024,256)\n",
    "        self.fc3 = nn.Linear(256,num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.batch_normalization_1 = nn.BatchNorm2d(32)\n",
    "        self.batch_normalization_2 = nn.BatchNorm2d(32)\n",
    "        self.batch_normalization_3 = nn.BatchNorm2d(64)\n",
    "        self.batch_normalization_4 = nn.BatchNorm2d(64)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(torch.relu(self.batch_normalization_1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.batch_normalization_2(self.conv2(x))))\n",
    "        x = self.pool(torch.relu(self.batch_normalization_3(self.conv3(x))))\n",
    "        x = torch.relu(self.batch_normalization_4(self.conv4(x)))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466e3fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=46656, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=29, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (batch_normalization_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_normalization_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_normalization_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_normalization_4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'sign_language_detection.pth'\n",
    "model = CNNModel(29)\n",
    "\n",
    "state_dict = torch.load('sign_language_detection.pth', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b7c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4e0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping= {'A': 0,\n",
    " 'B': 1,\n",
    " 'C': 2,\n",
    " 'D': 3,\n",
    " 'E': 4,\n",
    " 'F': 5,\n",
    " 'G': 6,\n",
    " 'H': 7,\n",
    " 'I': 8,\n",
    " 'J': 9,\n",
    " 'K': 10,\n",
    " 'L': 11,\n",
    " 'M': 12,\n",
    " 'N': 13,\n",
    " 'O': 14,\n",
    " 'P': 15,\n",
    " 'Q': 16,\n",
    " 'R': 17,\n",
    " 'S': 18,\n",
    " 'T': 19,\n",
    " 'U': 20,\n",
    " 'V': 21,\n",
    " 'W': 22,\n",
    " 'X': 23,\n",
    " 'Y': 24,\n",
    " 'Z': 25,\n",
    " 'del': 26,\n",
    " 'nothing': 27,\n",
    " 'space': 28}\n",
    "mapping = {v: k for k, v in mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6756482",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "detector = htm.handDetector()  \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands,x_min, y_min, x_max, y_max = detector.findHands(img)\n",
    "    h = np.array(hands)\n",
    "    cv2.imshow('Cropped Image', hands)\n",
    "    hand_tensor = transform(hands).unsqueeze(0)  \n",
    "    with torch.no_grad():\n",
    "        predictions = model(hand_tensor)\n",
    "        pred = torch.argmax(predictions,axis=1)\n",
    "        cv2.putText(img, str(mapping[pred.item()]),(x_min,y_min), cv2.FONT_HERSHEY_PLAIN, 3, (255,0,255), 3)\n",
    "        cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "        cv2.imshow('Image', img)\n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4105e627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
